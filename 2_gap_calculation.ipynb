{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tweet data(TW_TIME is Tweet timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 TW_NO   USER_NAME                    TW_TIME  \\\n",
      "0  1518974571860623361  Aromaaroro  2022-04-27 00:25:33+00:00   \n",
      "1  1518974084327276544  sakaki1981  2022-04-27 00:23:37+00:00   \n",
      "2  1518974042149031936     uuuuuuu  2022-04-27 00:23:27+00:00   \n",
      "3  1518973908552396800     paatram  2022-04-27 00:22:55+00:00   \n",
      "4  1518973615966138368    tare_lee  2022-04-27 00:21:45+00:00   \n",
      "\n",
      "                                             TW_TEXT  FAV  RT  \n",
      "0  #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「70連」達成！ガチャ結果をシェ...    0   0  \n",
      "1  #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「80連」達成！ガチャ結果をシェ...    0   0  \n",
      "2                               俺の中の発癌性物質が正午をお知らせします    0   0  \n",
      "3  #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「40連」達成！ガチャ結果をシェ...    0   0  \n",
      "4  #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「60連」達成！ガチャ結果をシェ...    0   0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets_noon_20220427.csv\",index_col=0)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert TW_TIME(str) to TW_TIME(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TW_TIME'] = pd.to_datetime(df['TW_TIME'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial and error...(ignore here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 12:00:00\n",
      "2022-04-27 00:25:33+00:00\n",
      "-1 days +12:25:33\n",
      "-41667.0\n"
     ]
    }
   ],
   "source": [
    "# a = df['TW_TIME'].dt.time\n",
    "c = datetime(df['TW_TIME'][0].year, df['TW_TIME'][0].month, df['TW_TIME'][0].day,12)\n",
    "print(c)\n",
    "print(df['TW_TIME'][0])\n",
    "print(df['TW_TIME'][0].replace(tzinfo=None)-c)\n",
    "d = df['TW_TIME'][0].replace(tzinfo=None)-c\n",
    "print(d.total_seconds())\n",
    "# print(datetime.time(hour=12))\n",
    "# print(a[0] - datetime.time(hour=12))\n",
    "# print(df['TW_TIME'][0].day)\n",
    "#df['TW_TIME'].dt.strftime('%Y-%m-%d') + datetime.timedelta(hours=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate GAP(=TW_TIME - noon) for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_calculation(x):\n",
    "    justnoon = datetime(x.year, x.month, x.day,12)\n",
    "    gap = (x.replace(tzinfo=None) - justnoon).total_seconds()\n",
    "    return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GAP'] = df['TW_TIME'].map(gap_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     TW_NO        USER_NAME                   TW_TIME  \\\n",
      "0      1518974571860623361       Aromaaroro 2022-04-27 00:25:33+00:00   \n",
      "1      1518974084327276544       sakaki1981 2022-04-27 00:23:37+00:00   \n",
      "2      1518974042149031936          uuuuuuu 2022-04-27 00:23:27+00:00   \n",
      "3      1518973908552396800          paatram 2022-04-27 00:22:55+00:00   \n",
      "4      1518973615966138368         tare_lee 2022-04-27 00:21:45+00:00   \n",
      "...                    ...              ...                       ...   \n",
      "14319  1516048171193217025  0Northernforest 2022-04-18 22:37:05+00:00   \n",
      "14320  1516048157435518980   healthcareITSG 2022-04-18 22:37:02+00:00   \n",
      "14321  1516047690823778308  elittle95377500 2022-04-18 22:35:10+00:00   \n",
      "14322  1516047184818741257      mushroom876 2022-04-18 22:33:10+00:00   \n",
      "14323  1516045374058024960       mx13171809 2022-04-18 22:25:58+00:00   \n",
      "\n",
      "                                                 TW_TEXT  FAV  RT      GAP  \n",
      "0      #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「70連」達成！ガチャ結果をシェ...    0   0 -41667.0  \n",
      "1      #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「80連」達成！ガチャ結果をシェ...    0   0 -41783.0  \n",
      "2                                   俺の中の発癌性物質が正午をお知らせします    0   0 -41793.0  \n",
      "3      #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「40連」達成！ガチャ結果をシェ...    0   0 -41825.0  \n",
      "4      #流星SW #30連以上確定 #ラッキーガチャ　の結果なんと「60連」達成！ガチャ結果をシェ...    0   0 -41895.0  \n",
      "...                                                  ...  ...  ..      ...  \n",
      "14319                だいたいですね、悪い話を水曜日正午になんか発表しないですし、この業界。    0   0  38225.0  \n",
      "14320  柿内正午の「プルーストを読む生活」に当てられて10年ぶりにブログで日記を書き始めた（しばらく...    6   1  38222.0  \n",
      "14321  【読書メーターの本のプレゼントに応募しました】 壊れそうな私を、君が救ってくれた。 第5回野...    0   0  38110.0  \n",
      "14322                    明日は初めての当直だ〜！次の日の正午まで仕事です頑張ります💪😇   12   0  37990.0  \n",
      "14323  商業もく亭正午ゆ正午ゆ商業目的　商業目的　商業目的商業目的　商業目的　正午ゆ正午ゆ商業目的商...    0   0  37558.0  \n",
      "\n",
      "[14324 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the result to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GAP'].to_csv(\"tweets_noon_ALL_gap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['TW_TEXT'].str.contains('正午なう')]['GAP'].to_csv(\"tweets_noon_NAU_gap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['TW_TEXT'].str.contains('もう正午')]['GAP'].to_csv(\"tweets_noon_MOU_gap.csv\")\n",
    "df[df['TW_TEXT'].str.contains('まだ正午')]['GAP'].to_csv(\"tweets_noon_MADA_gap.csv\")\n",
    "df[df['TW_TEXT'].str.contains('今正午')]['GAP'].to_csv(\"tweets_noon_IMA_gap.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4a7a4a78ef411cca512ec91137b8be66fe0a34d5da5a9f541833801df813a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
